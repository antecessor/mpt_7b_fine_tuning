{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "shared-evans",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrmohebbian/anaconda3/envs/hugging/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/mrmohebbian/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-7b/d8304854d4877849c3c0a78f3469512a84419e84/attention.py:148: UserWarning: Using `attn_impl: torch`. If your model does not use `alibi` or `prefix_lm` we recommend using `attn_impl: flash` otherwise we recommend using `attn_impl: triton`.\n",
      "  warnings.warn('Using `attn_impl: torch`. If your model does not use `alibi` or ' + '`prefix_lm` we recommend using `attn_impl: flash` otherwise ' + 'we recommend using `attn_impl: triton`.')\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPTForCausalLM(\n",
       "  (transformer): MPTModel(\n",
       "    (wte): Embedding(50432, 4096)\n",
       "    (emb_drop): Dropout(p=0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (1): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (2): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (3): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (4): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (5): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (6): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (7): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (8): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (9): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (10): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (11): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (12): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (13): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (14): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (15): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (16): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (17): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (18): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (19): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (20): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (21): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (22): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (23): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (24): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (25): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (26): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (27): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (28): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (29): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (30): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (31): MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm_f): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "  'mosaicml/mpt-7b',\n",
    "  trust_remote_code=True,\n",
    "  torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.eval()\n",
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cooked-youth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  6 20:58:09 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   47C    P0    66W / 300W |  13496MiB / 16160MiB |     26%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   43C    P0    37W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   42C    P0    40W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   44C    P0    44W / 300W |      3MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    114788      C   ...3/envs/hugging/bin/python    13493MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelsize: 6649.3M parameters\n"
     ]
    }
   ],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"Modelsize: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "refined-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('mosaicml/mpt-7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becoming-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\\\n",
    "image_path = \"/mnt/image.png\"\n",
    "\n",
    "# load image\n",
    "\"\"\"\n",
    "tokenized_example = tokenizer(txt, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "spectacular-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5695,    64,  3967,   426, 13357,    78,  2649,    16,  5695,    15,\n",
       "          8567,     3,   187,   187,     4,  3301,  2460,   187]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moved-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenized_example['input_ids'].to('cuda:0'), max_new_tokens=150, do_sample=False, top_k=5, top_p=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surface-arena",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path = \"/mnt/image.png\"\n",
      "\n",
      "# load image\n",
      "image = cv2.imread(image_path)\n",
      "\n",
      "# convert to grayscale\n",
      "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "# blur\n",
      "blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
      "\n",
      "# find edges\n",
      "edged = cv2.Canny(blur, 50, 150)\n",
      "\n",
      "# find contours\n",
      "contours, hierarchy = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
      "\n",
      "# draw contours\n",
      "for cnt in contours:\n",
      "    cv2.drawContours\n"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(answer[0].rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "temporal-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text = \"\"\"\\\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.read(image_path)\n",
    "\"\"\"\n",
    "tokenized_answer = tokenizer.encode(answer_text ,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aggressive-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**tokenized_example.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vertical-seller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 50432])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tested-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "functioning-minutes",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50432])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_token_output = outputs.logits[0,-1].view(1,-1)\n",
    "last_token_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "promising-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5695, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(last_token_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reported-republican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4064])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_answer.shape\n",
    "labels = tokenized_answer[0][0].view(1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arctic-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight   Modelsize: 206.6M parameters\n",
      "transformer.wte.weight False\n",
      "transformer.blocks.0.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.0.norm_1.weight False\n",
      "transformer.blocks.0.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.0.attn.Wqkv.weight False\n",
      "transformer.blocks.0.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.0.attn.out_proj.weight False\n",
      "transformer.blocks.0.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.0.norm_2.weight False\n",
      "transformer.blocks.0.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.0.ffn.up_proj.weight False\n",
      "transformer.blocks.0.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.0.ffn.down_proj.weight False\n",
      "transformer.blocks.1.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.1.norm_1.weight False\n",
      "transformer.blocks.1.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.1.attn.Wqkv.weight False\n",
      "transformer.blocks.1.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.1.attn.out_proj.weight False\n",
      "transformer.blocks.1.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.1.norm_2.weight False\n",
      "transformer.blocks.1.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.1.ffn.up_proj.weight False\n",
      "transformer.blocks.1.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.1.ffn.down_proj.weight False\n",
      "transformer.blocks.2.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.2.norm_1.weight False\n",
      "transformer.blocks.2.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.2.attn.Wqkv.weight False\n",
      "transformer.blocks.2.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.2.attn.out_proj.weight False\n",
      "transformer.blocks.2.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.2.norm_2.weight False\n",
      "transformer.blocks.2.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.2.ffn.up_proj.weight False\n",
      "transformer.blocks.2.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.2.ffn.down_proj.weight False\n",
      "transformer.blocks.3.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.3.norm_1.weight False\n",
      "transformer.blocks.3.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.3.attn.Wqkv.weight False\n",
      "transformer.blocks.3.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.3.attn.out_proj.weight False\n",
      "transformer.blocks.3.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.3.norm_2.weight False\n",
      "transformer.blocks.3.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.3.ffn.up_proj.weight False\n",
      "transformer.blocks.3.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.3.ffn.down_proj.weight False\n",
      "transformer.blocks.4.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.4.norm_1.weight False\n",
      "transformer.blocks.4.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.4.attn.Wqkv.weight False\n",
      "transformer.blocks.4.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.4.attn.out_proj.weight False\n",
      "transformer.blocks.4.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.4.norm_2.weight False\n",
      "transformer.blocks.4.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.4.ffn.up_proj.weight False\n",
      "transformer.blocks.4.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.4.ffn.down_proj.weight False\n",
      "transformer.blocks.5.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.5.norm_1.weight False\n",
      "transformer.blocks.5.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.5.attn.Wqkv.weight False\n",
      "transformer.blocks.5.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.5.attn.out_proj.weight False\n",
      "transformer.blocks.5.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.5.norm_2.weight False\n",
      "transformer.blocks.5.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.5.ffn.up_proj.weight False\n",
      "transformer.blocks.5.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.5.ffn.down_proj.weight False\n",
      "transformer.blocks.6.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.6.norm_1.weight False\n",
      "transformer.blocks.6.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.6.attn.Wqkv.weight False\n",
      "transformer.blocks.6.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.6.attn.out_proj.weight False\n",
      "transformer.blocks.6.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.6.norm_2.weight False\n",
      "transformer.blocks.6.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.6.ffn.up_proj.weight False\n",
      "transformer.blocks.6.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.6.ffn.down_proj.weight False\n",
      "transformer.blocks.7.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.7.norm_1.weight False\n",
      "transformer.blocks.7.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.7.attn.Wqkv.weight False\n",
      "transformer.blocks.7.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.7.attn.out_proj.weight False\n",
      "transformer.blocks.7.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.7.norm_2.weight False\n",
      "transformer.blocks.7.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.7.ffn.up_proj.weight False\n",
      "transformer.blocks.7.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.7.ffn.down_proj.weight False\n",
      "transformer.blocks.8.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.8.norm_1.weight False\n",
      "transformer.blocks.8.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.8.attn.Wqkv.weight False\n",
      "transformer.blocks.8.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.8.attn.out_proj.weight False\n",
      "transformer.blocks.8.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.8.norm_2.weight False\n",
      "transformer.blocks.8.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.8.ffn.up_proj.weight False\n",
      "transformer.blocks.8.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.8.ffn.down_proj.weight False\n",
      "transformer.blocks.9.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.9.norm_1.weight False\n",
      "transformer.blocks.9.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.9.attn.Wqkv.weight False\n",
      "transformer.blocks.9.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.9.attn.out_proj.weight False\n",
      "transformer.blocks.9.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.9.norm_2.weight False\n",
      "transformer.blocks.9.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.9.ffn.up_proj.weight False\n",
      "transformer.blocks.9.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.9.ffn.down_proj.weight False\n",
      "transformer.blocks.10.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.10.norm_1.weight False\n",
      "transformer.blocks.10.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.10.attn.Wqkv.weight False\n",
      "transformer.blocks.10.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.10.attn.out_proj.weight False\n",
      "transformer.blocks.10.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.10.norm_2.weight False\n",
      "transformer.blocks.10.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.10.ffn.up_proj.weight False\n",
      "transformer.blocks.10.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.10.ffn.down_proj.weight False\n",
      "transformer.blocks.11.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.11.norm_1.weight False\n",
      "transformer.blocks.11.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.11.attn.Wqkv.weight False\n",
      "transformer.blocks.11.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.11.attn.out_proj.weight False\n",
      "transformer.blocks.11.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.11.norm_2.weight False\n",
      "transformer.blocks.11.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.11.ffn.up_proj.weight False\n",
      "transformer.blocks.11.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.11.ffn.down_proj.weight False\n",
      "transformer.blocks.12.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.12.norm_1.weight False\n",
      "transformer.blocks.12.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.12.attn.Wqkv.weight False\n",
      "transformer.blocks.12.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.12.attn.out_proj.weight False\n",
      "transformer.blocks.12.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.12.norm_2.weight False\n",
      "transformer.blocks.12.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.12.ffn.up_proj.weight False\n",
      "transformer.blocks.12.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.12.ffn.down_proj.weight False\n",
      "transformer.blocks.13.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.13.norm_1.weight False\n",
      "transformer.blocks.13.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.13.attn.Wqkv.weight False\n",
      "transformer.blocks.13.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.13.attn.out_proj.weight False\n",
      "transformer.blocks.13.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.13.norm_2.weight False\n",
      "transformer.blocks.13.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.13.ffn.up_proj.weight False\n",
      "transformer.blocks.13.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.13.ffn.down_proj.weight False\n",
      "transformer.blocks.14.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.14.norm_1.weight False\n",
      "transformer.blocks.14.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.14.attn.Wqkv.weight False\n",
      "transformer.blocks.14.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.14.attn.out_proj.weight False\n",
      "transformer.blocks.14.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.14.norm_2.weight False\n",
      "transformer.blocks.14.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.14.ffn.up_proj.weight False\n",
      "transformer.blocks.14.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.14.ffn.down_proj.weight False\n",
      "transformer.blocks.15.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.15.norm_1.weight False\n",
      "transformer.blocks.15.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.15.attn.Wqkv.weight False\n",
      "transformer.blocks.15.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.15.attn.out_proj.weight False\n",
      "transformer.blocks.15.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.15.norm_2.weight False\n",
      "transformer.blocks.15.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.15.ffn.up_proj.weight False\n",
      "transformer.blocks.15.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.15.ffn.down_proj.weight False\n",
      "transformer.blocks.16.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.16.norm_1.weight False\n",
      "transformer.blocks.16.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.16.attn.Wqkv.weight False\n",
      "transformer.blocks.16.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.16.attn.out_proj.weight False\n",
      "transformer.blocks.16.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.16.norm_2.weight False\n",
      "transformer.blocks.16.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.16.ffn.up_proj.weight False\n",
      "transformer.blocks.16.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.16.ffn.down_proj.weight False\n",
      "transformer.blocks.17.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.17.norm_1.weight False\n",
      "transformer.blocks.17.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.17.attn.Wqkv.weight False\n",
      "transformer.blocks.17.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.17.attn.out_proj.weight False\n",
      "transformer.blocks.17.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.17.norm_2.weight False\n",
      "transformer.blocks.17.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.17.ffn.up_proj.weight False\n",
      "transformer.blocks.17.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.17.ffn.down_proj.weight False\n",
      "transformer.blocks.18.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.18.norm_1.weight False\n",
      "transformer.blocks.18.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.18.attn.Wqkv.weight False\n",
      "transformer.blocks.18.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.18.attn.out_proj.weight False\n",
      "transformer.blocks.18.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.18.norm_2.weight False\n",
      "transformer.blocks.18.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.18.ffn.up_proj.weight False\n",
      "transformer.blocks.18.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.18.ffn.down_proj.weight False\n",
      "transformer.blocks.19.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.19.norm_1.weight False\n",
      "transformer.blocks.19.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.19.attn.Wqkv.weight False\n",
      "transformer.blocks.19.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.19.attn.out_proj.weight False\n",
      "transformer.blocks.19.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.19.norm_2.weight False\n",
      "transformer.blocks.19.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.19.ffn.up_proj.weight False\n",
      "transformer.blocks.19.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.19.ffn.down_proj.weight False\n",
      "transformer.blocks.20.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.20.norm_1.weight False\n",
      "transformer.blocks.20.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.20.attn.Wqkv.weight False\n",
      "transformer.blocks.20.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.20.attn.out_proj.weight False\n",
      "transformer.blocks.20.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.20.norm_2.weight False\n",
      "transformer.blocks.20.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.20.ffn.up_proj.weight False\n",
      "transformer.blocks.20.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.20.ffn.down_proj.weight False\n",
      "transformer.blocks.21.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.21.norm_1.weight False\n",
      "transformer.blocks.21.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.21.attn.Wqkv.weight False\n",
      "transformer.blocks.21.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.21.attn.out_proj.weight False\n",
      "transformer.blocks.21.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.21.norm_2.weight False\n",
      "transformer.blocks.21.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.21.ffn.up_proj.weight False\n",
      "transformer.blocks.21.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.21.ffn.down_proj.weight False\n",
      "transformer.blocks.22.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.22.norm_1.weight False\n",
      "transformer.blocks.22.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.22.attn.Wqkv.weight False\n",
      "transformer.blocks.22.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.22.attn.out_proj.weight False\n",
      "transformer.blocks.22.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.22.norm_2.weight False\n",
      "transformer.blocks.22.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.22.ffn.up_proj.weight False\n",
      "transformer.blocks.22.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.22.ffn.down_proj.weight False\n",
      "transformer.blocks.23.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.23.norm_1.weight False\n",
      "transformer.blocks.23.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.23.attn.Wqkv.weight False\n",
      "transformer.blocks.23.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.23.attn.out_proj.weight False\n",
      "transformer.blocks.23.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.23.norm_2.weight False\n",
      "transformer.blocks.23.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.23.ffn.up_proj.weight False\n",
      "transformer.blocks.23.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.23.ffn.down_proj.weight False\n",
      "transformer.blocks.24.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.24.norm_1.weight False\n",
      "transformer.blocks.24.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.24.attn.Wqkv.weight False\n",
      "transformer.blocks.24.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.24.attn.out_proj.weight False\n",
      "transformer.blocks.24.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.24.norm_2.weight False\n",
      "transformer.blocks.24.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.24.ffn.up_proj.weight False\n",
      "transformer.blocks.24.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.24.ffn.down_proj.weight False\n",
      "transformer.blocks.25.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.25.norm_1.weight False\n",
      "transformer.blocks.25.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.25.attn.Wqkv.weight False\n",
      "transformer.blocks.25.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.25.attn.out_proj.weight False\n",
      "transformer.blocks.25.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.25.norm_2.weight False\n",
      "transformer.blocks.25.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.25.ffn.up_proj.weight False\n",
      "transformer.blocks.25.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.25.ffn.down_proj.weight False\n",
      "transformer.blocks.26.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.26.norm_1.weight False\n",
      "transformer.blocks.26.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.26.attn.Wqkv.weight False\n",
      "transformer.blocks.26.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.26.attn.out_proj.weight False\n",
      "transformer.blocks.26.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.26.norm_2.weight False\n",
      "transformer.blocks.26.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.26.ffn.up_proj.weight False\n",
      "transformer.blocks.26.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.26.ffn.down_proj.weight False\n",
      "transformer.blocks.27.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.27.norm_1.weight False\n",
      "transformer.blocks.27.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.27.attn.Wqkv.weight False\n",
      "transformer.blocks.27.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.27.attn.out_proj.weight False\n",
      "transformer.blocks.27.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.27.norm_2.weight False\n",
      "transformer.blocks.27.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.27.ffn.up_proj.weight False\n",
      "transformer.blocks.27.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.27.ffn.down_proj.weight False\n",
      "transformer.blocks.28.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.28.norm_1.weight False\n",
      "transformer.blocks.28.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.28.attn.Wqkv.weight False\n",
      "transformer.blocks.28.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.28.attn.out_proj.weight False\n",
      "transformer.blocks.28.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.28.norm_2.weight False\n",
      "transformer.blocks.28.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.28.ffn.up_proj.weight False\n",
      "transformer.blocks.28.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.28.ffn.down_proj.weight False\n",
      "transformer.blocks.29.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.29.norm_1.weight False\n",
      "transformer.blocks.29.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.29.attn.Wqkv.weight False\n",
      "transformer.blocks.29.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.29.attn.out_proj.weight False\n",
      "transformer.blocks.29.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.29.norm_2.weight False\n",
      "transformer.blocks.29.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.29.ffn.up_proj.weight False\n",
      "transformer.blocks.29.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.29.ffn.down_proj.weight False\n",
      "transformer.blocks.30.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.30.norm_1.weight False\n",
      "transformer.blocks.30.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.30.attn.Wqkv.weight False\n",
      "transformer.blocks.30.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.30.attn.out_proj.weight False\n",
      "transformer.blocks.30.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.30.norm_2.weight False\n",
      "transformer.blocks.30.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.30.ffn.up_proj.weight False\n",
      "transformer.blocks.30.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.30.ffn.down_proj.weight False\n",
      "transformer.blocks.31.norm_1.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.31.norm_1.weight True\n",
      "transformer.blocks.31.attn.Wqkv.weight   Modelsize: 50.3M parameters\n",
      "transformer.blocks.31.attn.Wqkv.weight True\n",
      "transformer.blocks.31.attn.out_proj.weight   Modelsize: 16.8M parameters\n",
      "transformer.blocks.31.attn.out_proj.weight True\n",
      "transformer.blocks.31.norm_2.weight   Modelsize: 0.0M parameters\n",
      "transformer.blocks.31.norm_2.weight True\n",
      "transformer.blocks.31.ffn.up_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.31.ffn.up_proj.weight True\n",
      "transformer.blocks.31.ffn.down_proj.weight   Modelsize: 67.1M parameters\n",
      "transformer.blocks.31.ffn.down_proj.weight True\n",
      "transformer.norm_f.weight   Modelsize: 0.0M parameters\n",
      "transformer.norm_f.weight False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}   Modelsize: {param.numel()/1000**2:.1f}M parameters\")\n",
    "    if \"31\" not in name:\n",
    "        param.requires_grad = False\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "banned-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelsize: 201.3M parameters\n"
     ]
    }
   ],
   "source": [
    "params = sum(t.numel() for t in model.transformer.blocks[-1].parameters())\n",
    "print(f\"Modelsize: {params/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "retired-italic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrmohebbian/anaconda3/envs/hugging/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lossfct = torch.nn.CrossEntropyLoss()\n",
    "optimizer = transformers.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "promising-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tokenized_answer[0][0].view(1)\n",
    "loss = lossfct(last_token_output,labels.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "perfect-spiritual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.671875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "disabled-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad(set_to_none=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wicked-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenized_example['input_ids'].to('cuda:0'), max_new_tokens=50, do_sample=False, top_k=5, top_p=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "otherwise-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path = \"/mnt/image.png\"\n",
      "\n",
      "# load image\n",
      "from PIL import Image\n",
      "from PIL import ImageDraw\n",
      "from PIL import ImageFont\n",
      "from PIL import ImageFilter\n",
      "from PIL import ImageEnhance\n",
      "from PIL import ImageOps\n",
      "from PIL import ImageChops\n",
      "from PIL import ImageColor\n",
      "from PIL import ImageTk\n",
      "from PIL import ImageGrab\n",
      "from PIL import ImageSequence\n",
      "from PIL import ImageSequenceClip\n",
      "from PIL import ImageSequenceClipDraw\n",
      "from PIL import ImageSequenceClipDraw\n",
      "from PIL import ImageSequenceClipDraw\n",
      "from PIL import ImageSequenceClipDraw\n",
      "from PIL import ImageSequenceClipDraw\n",
      "from PIL import ImageSequenceClipDraw\n",
      "from PIL import ImageSequenceClip\n"
     ]
    }
   ],
   "source": [
    "answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(answer[0].rstrip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "hugging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
